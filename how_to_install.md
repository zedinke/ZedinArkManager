# üêß Linux telep√≠t√©si √∫tmutat√≥

## üìã El≈ëfelt√©telek

### 1. Rendszer k√∂vetelm√©nyek

- **OS**: Debian 12 (vagy hasonl√≥ Linux disztrib√∫ci√≥)
- **Python**: 3.8 vagy √∫jabb
- **RAM**: Minimum 8GB (aj√°nlott 16GB+)
- **T√°rhely**: Minimum 10GB szabad hely

### 2. Rendszerfriss√≠t√©s

```bash
sudo apt update
sudo apt upgrade -y
```

### 3. Python telep√≠t√©se (ha nincs)

```bash
sudo apt install python3 python3-pip python3-venv -y
```

### 4. Git telep√≠t√©se (ha nincs)

```bash
sudo apt install git -y
```

---

## üöÄ Telep√≠t√©s l√©p√©sei

### 1. l√©p√©s: Repository kl√≥noz√°sa

```bash
git clone https://github.com/zedinke/ZedinArkManager.git
cd ZedinArkManager
```

### 2. l√©p√©s: Automatikus telep√≠t√©s

```bash
chmod +x installers/install.sh
./installers/install.sh
```

A script:
- L√©trehozza a sz√ºks√©ges k√∂nyvt√°rakat
- Telep√≠ti a Python f√ºgg≈ës√©geket
- Ellen≈ërzi az Ollama telep√≠t√©s√©t
- L√©trehozza a `.env` f√°jlt

### 3. l√©p√©s: Ollama telep√≠t√©se

Ha m√©g nincs telep√≠tve az Ollama:

```bash
curl https://ollama.com/install.sh | sh
```

Vagy manu√°lisan:
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

### 4. l√©p√©s: Modell telep√≠t√©se

```bash
# Ollama ind√≠t√°sa (ha m√©g nem fut)
ollama serve &

# Modell let√∂lt√©se (ez id≈ëbe telhet, ~4-5GB)
ollama pull llama3.1:8b
```

Egy√©b modellek:
```bash
ollama pull codellama       # Code-specific modell
ollama pull mistral         # Kisebb, gyorsabb modell
ollama pull deepseek-coder  # Code generation
```

### 5. l√©p√©s: K√∂rnyezeti v√°ltoz√≥k be√°ll√≠t√°sa

Szerkeszd a `.env` f√°jlt (ha sz√ºks√©ges):

```bash
nano .env
```

P√©lda be√°ll√≠t√°sok:
```env
# Ollama be√°ll√≠t√°sok
OLLAMA_URL=http://localhost:11434
DEFAULT_MODEL=llama3.1:8b

# Projekt be√°ll√≠t√°sok
PROJECT_BASE_PATH=.

# Optimaliz√°ci√≥ (opcion√°lis)
OLLAMA_NUM_GPU_LAYERS=35    # GPU r√©tegek sz√°ma (ha van GPU)
OLLAMA_NUM_THREADS=32       # CPU sz√°lak sz√°ma (32 maghoz)
```

### 6. l√©p√©s: Rendszer ind√≠t√°sa

```bash
chmod +x start.sh
./start.sh
```

A script:
- Ellen≈ërzi az Ollama fut√°s√°t
- Ellen≈ërzi a modellek telep√≠t√©s√©t
- Ind√≠tja a FastAPI szervert

---

## üîß Manu√°lis telep√≠t√©s (ha az automatikus nem m≈±k√∂dik)

### Python f√ºgg≈ës√©gek telep√≠t√©se

```bash
pip3 install --upgrade pip
pip3 install -r installers/requirements.txt
```

### K√∂nyvt√°rak l√©trehoz√°sa

```bash
mkdir -p logs data/cache data/memory projects
```

### K√∂rnyezeti v√°ltoz√≥k be√°ll√≠t√°sa

```bash
export OLLAMA_URL="http://localhost:11434"
export DEFAULT_MODEL="llama3.1:8b"
export PROJECT_BASE_PATH="."
```

Vagy √°lland√≥ be√°ll√≠t√°shoz a `.env` f√°jlban.

---

## üèÉ Rendszer ind√≠t√°sa

### Opci√≥ 1: Automatikus ind√≠t√≥ script (aj√°nlott)

```bash
./start.sh
```

### Opci√≥ 2: Manu√°lis ind√≠t√°s

#### Ollama ind√≠t√°sa h√°t√©rben:

```bash
nohup ollama serve > logs/ollama.log 2>&1 &
```

#### FastAPI szerver ind√≠t√°sa:

```bash
python3 main.py
```

Vagy uvicorn-nel k√∂zvetlen√ºl:

```bash
uvicorn main:app --host 0.0.0.0 --port 8000
```

### Opci√≥ 3: Systemd szolg√°ltat√°sk√©nt (√©les k√∂rnyezet)

L√©trehozni egy `/etc/systemd/system/zedinarkmanager.service` f√°jlt:

```ini
[Unit]
Description=ZedinArkManager API Server
After=network.target

[Service]
Type=simple
User=your-user
WorkingDirectory=/path/to/ZedinArkManager
EnvironmentFile=/path/to/ZedinArkManager/.env
ExecStart=/usr/bin/python3 /path/to/ZedinArkManager/main.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

Akt√≠v√°l√°s:

```bash
sudo systemctl daemon-reload
sudo systemctl enable zedinarkmanager
sudo systemctl start zedinarkmanager
sudo systemctl status zedinarkmanager
```

---

## ‚úÖ Ellen≈ërz√©s

### 1. Health check

```bash
curl http://localhost:8000/health
```

V√°lasz p√©lda:
```json
{
  "status": "healthy",
  "ollama_connected": true,
  "base_path": ".",
  "default_model": "llama3.1:8b"
}
```

### 2. API dokument√°ci√≥

Nyisd meg b√∂ng√©sz≈ëben:
```
http://localhost:8000/docs
```

### 3. Telep√≠tett modellek list√°z√°sa

```bash
curl http://localhost:8000/api/models
```

---

## üîç Hibaelh√°r√≠t√°s

### Ollama nem fut

```bash
# Ellen≈ërz√©s
curl http://localhost:11434/api/tags

# Ind√≠t√°s
ollama serve

# Logok ellen≈ërz√©se
tail -f logs/ollama.log
```

### Python f√ºgg≈ës√©gek hi√°nyoznak

```bash
pip3 install -r installers/requirements.txt
```

### Port m√°r haszn√°latban

```bash
# Melyik process haszn√°lja a portot?
sudo lsof -i :8000

# Kill process
sudo kill -9 <PID>
```

### Jogosults√°g hib√°k

```bash
# Jogosults√°gok be√°ll√≠t√°sa
chmod +x start.sh
chmod +x installers/install.sh
chmod -R 755 logs data projects
```

### Log f√°jlok ellen≈ërz√©se

```bash
tail -f logs/app.log
tail -f logs/ollama.log
```

---

## üìù Friss√≠t√©s

### K√≥d friss√≠t√©se

```bash
git pull origin main
pip3 install -r installers/requirements.txt --upgrade
```

### Ollama friss√≠t√©se

```bash
ollama --version
# √öjabb verzi√≥ let√∂lt√©se
curl https://ollama.com/install.sh | sh
```

---

## üîê Biztons√°g (√©les k√∂rnyezet)

1. **CORS korl√°toz√°s**: Szerkeszd a `main.py`-t, √©s korl√°tozd az `allow_origins`-t
2. **Autentik√°ci√≥**: Adjon hozz√° API kulcs autentik√°ci√≥t
3. **HTTPS**: Haszn√°lj Nginx reverse proxy-t SSL-lel
4. **Firewall**: Nyisd meg csak a sz√ºks√©ges portokat

---

## üìû Tov√°bbi inform√°ci√≥k

- API dokument√°ci√≥: `http://localhost:8000/docs`
- Projekt strukt√∫ra: `docs/PROJECT_STRUCTURE.md`
- Haszn√°lati √∫tmutat√≥: `docs/USAGE_GUIDE.md`

---

**Telep√≠t√©s befejezve! üéâ**


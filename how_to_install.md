# üêß Linux telep√≠t√©si √∫tmutat√≥ - L√©p√©sr≈ël l√©p√©sre

## üìã El≈ëfelt√©telek ellen≈ërz√©se

### 1. l√©p√©s: Rendszerfriss√≠t√©s

```bash
sudo apt update
sudo apt upgrade -y
```

### 2. l√©p√©s: Python telep√≠t√©se/ellen≈ërz√©se

```bash
# Python verzi√≥ ellen≈ërz√©se
python3 --version

# Ha nincs telep√≠tve Python 3.8 vagy √∫jabb:
sudo apt install python3 python3-pip python3-venv -y
```

### 3. l√©p√©s: Git telep√≠t√©se/ellen≈ërz√©se

```bash
# Git ellen≈ërz√©se
git --version

# Ha nincs telep√≠tve:
sudo apt install git -y
```

---

## üöÄ Telep√≠t√©s l√©p√©sei

### 1. l√©p√©s: Repository kl√≥noz√°sa

```bash
# Kl√≥nozd le a repository-t
git clone https://github.com/zedinke/ZedinArkManager.git

# L√©pj be a mapp√°ba
cd ZedinArkManager
```

### 2. l√©p√©s: Automatikus telep√≠t≈ë futtat√°sa

```bash
# Telep√≠t≈ë script futtathat√≥v√° t√©tele
chmod +x installers/install.sh

# Telep√≠t≈ë futtat√°sa
./installers/install.sh
```

**Mit csin√°l a telep√≠t≈ë?**
- ‚úÖ L√©trehozza a sz√ºks√©ges mapp√°kat (`logs`, `data`, `projects`)
- ‚úÖ Telep√≠ti a Python f√ºgg≈ës√©geket
- ‚úÖ Ellen≈ërzi az Ollama telep√≠t√©s√©t
- ‚úÖ L√©trehozza a `.env` konfigur√°ci√≥s f√°jlt

### 3. l√©p√©s: Ollama telep√≠t√©se

**Ha m√©g nincs telep√≠tve az Ollama:**

```bash
# Ollama telep√≠t√©se
curl https://ollama.com/install.sh | sh
```

**Ellen≈ërz√©s:**

```bash
# Ollama verzi√≥ ellen≈ërz√©se
ollama --version
```

### 4. l√©p√©s: Ollama ind√≠t√°sa

**Opci√≥ 1: H√°t√©rben ind√≠t√°s (aj√°nlott)**

```bash
# Ollama ind√≠t√°sa h√°t√©rben
nohup ollama serve > logs/ollama.log 2>&1 &

# Ellen≈ërz√©s, hogy fut-e
curl http://localhost:11434/api/tags
```

**Opci√≥ 2: El≈ët√©rben ind√≠t√°s**

```bash
# Ollama ind√≠t√°sa el≈ët√©rben (Ctrl+C-vel le√°ll√≠that√≥)
ollama serve
```

### 5. l√©p√©s: Modell telep√≠t√©se

```bash
# A magyarul j√≥l besz√©l≈ë modell let√∂lt√©se (~4-5GB, ez id≈ëbe telhet)
ollama pull llama3.1:8b
```

**Alternat√≠v modellek (ha sz√ºks√©ges):**

```bash
ollama pull codellama       # K√≥d-gener√°l√°sra optimaliz√°lt
ollama pull mistral         # Kisebb, gyorsabb modell
ollama pull deepseek-coder  # Code generation modell
```

**Ellen≈ërz√©s, hogy telep√≠tve van-e:**

```bash
# Telep√≠tett modellek list√°z√°sa
ollama list

# Vagy
curl http://localhost:11434/api/tags
```

### 6. l√©p√©s: K√∂rnyezeti v√°ltoz√≥k be√°ll√≠t√°sa

**Szerkeszd a `.env` f√°jlt (ha sz√ºks√©ges):**

```bash
nano .env
```

**Alap√©rtelmezett √©rt√©kek (√°ltal√°ban ezek j√≥k):**

```env
# Ollama be√°ll√≠t√°sok
OLLAMA_URL=http://localhost:11434
DEFAULT_MODEL=llama3.1:8b

# Projekt be√°ll√≠t√°sok
PROJECT_BASE_PATH=.

# Optimaliz√°ci√≥ (opcion√°lis - a te szerveredhez):
OLLAMA_NUM_GPU_LAYERS=      # Ha van GPU, pl: 35
OLLAMA_NUM_THREADS=32       # 32 maghoz = 32 sz√°l
```

**Vagy k√∂rnyezeti v√°ltoz√≥k√©nt (ha nem haszn√°lod a .env f√°jlt):**

```bash
export OLLAMA_URL="http://localhost:11434"
export DEFAULT_MODEL="llama3.1:8b"
export PROJECT_BASE_PATH="."
export OLLAMA_NUM_THREADS="32"
```

### 7. l√©p√©s: Rendszer ind√≠t√°sa

**Ind√≠t√≥ script haszn√°lata (aj√°nlott):**

```bash
# Ind√≠t√≥ script futtathat√≥v√° t√©tele
chmod +x start.sh

# Rendszer ind√≠t√°sa
./start.sh
```

**Mit csin√°l az ind√≠t√≥ script?**
- ‚úÖ Ellen≈ërzi, hogy az Ollama fut-e
- ‚úÖ Ellen≈ërzi a modellek telep√≠t√©s√©t (ha nincs, k√©rdezi, hogy telep√≠tse-e)
- ‚úÖ Ellen≈ërzi a Python f√ºgg≈ës√©geket
- ‚úÖ Bet√∂lti a k√∂rnyezeti v√°ltoz√≥kat (`.env` f√°jlb√≥l)
- ‚úÖ Ind√≠tja a FastAPI szervert

### 8. l√©p√©s: Ellen≈ërz√©s, hogy minden m≈±k√∂dik

**1. Health check (termin√°lb√≥l):**

```bash
curl http://localhost:8000/health
```

**V√°rhat√≥ v√°lasz:**
```json
{
  "status": "healthy",
  "ollama_connected": true,
  "base_path": ".",
  "default_model": "llama3.1:8b"
}
```

**2. API dokument√°ci√≥ megnyit√°sa (b√∂ng√©sz≈ëben):**

```
http://localhost:8000/docs
```

**3. Telep√≠tett modellek ellen≈ërz√©se:**

```bash
curl http://localhost:8000/api/models
```

---

## ‚úÖ Telep√≠t√©s k√©sz!

Ha minden l√©p√©s sikeres volt, a rendszer most fut √©s el√©rhet≈ë:

- **API**: http://localhost:8000
- **API Dokument√°ci√≥**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health

---

## üîß Manu√°lis telep√≠t√©s (ha az automatikus nem m≈±k√∂dik)

### 1. Python f√ºgg≈ës√©gek telep√≠t√©se

```bash
# pip friss√≠t√©se
pip3 install --upgrade pip

# F√ºgg≈ës√©gek telep√≠t√©se
pip3 install -r installers/requirements.txt
```

### 2. Mapp√°k l√©trehoz√°sa

```bash
mkdir -p logs data/cache data/memory projects
```

### 3. FastAPI szerver ind√≠t√°sa (manu√°lisan)

```bash
# K√∂zvetlen√ºl Python-nal
python3 main.py

# Vagy uvicorn-nel
uvicorn main:app --host 0.0.0.0 --port 8000
```

---

## üèÉ Rendszer ind√≠t√°sa (k√©s≈ëbbi haszn√°lat)

### Gyors ind√≠t√°s

```bash
./start.sh
```

### H√°t√©rben ind√≠t√°s

```bash
# Ollama h√°t√©rben (ha m√©g nem fut)
nohup ollama serve > logs/ollama.log 2>&1 &

# FastAPI h√°t√©rben
nohup python3 main.py > logs/app.log 2>&1 &
```

### Systemd szolg√°ltat√°sk√©nt (√©les k√∂rnyezet)

**1. Szolg√°ltat√°s f√°jl l√©trehoz√°sa:**

```bash
sudo nano /etc/systemd/system/zedinarkmanager.service
```

**2. Tartalom:**

```ini
[Unit]
Description=ZedinArkManager API Server
After=network.target

[Service]
Type=simple
User=your-username
WorkingDirectory=/home/your-username/ZedinArkManager
EnvironmentFile=/home/your-username/ZedinArkManager/.env
ExecStart=/usr/bin/python3 /home/your-username/ZedinArkManager/main.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

**3. Szolg√°ltat√°s aktiv√°l√°sa:**

```bash
# Systemd √∫jrat√∂lt√©se
sudo systemctl daemon-reload

# Szolg√°ltat√°s enged√©lyez√©se (indul√°s rendszerind√≠t√°skor)
sudo systemctl enable zedinarkmanager

# Szolg√°ltat√°s ind√≠t√°sa
sudo systemctl start zedinarkmanager

# √Ållapot ellen≈ërz√©se
sudo systemctl status zedinarkmanager
```

---

## üîç Hibaelh√°r√≠t√°s

### Ollama nem fut

```bash
# Ellen≈ërz√©s
curl http://localhost:11434/api/tags

# Ha nem fut, ind√≠tsd el:
ollama serve

# Vagy h√°t√©rben:
nohup ollama serve > logs/ollama.log 2>&1 &
```

### Ollama kapcsolati hiba

```bash
# Ellen≈ërizd, hogy az Ollama fut-e
ps aux | grep ollama

# Ha nem fut, ind√≠tsd el
ollama serve &

# V√°rj 2-3 m√°sodpercet, majd pr√≥b√°ld √∫jra
sleep 3
curl http://localhost:11434/api/tags
```

### Modell nincs telep√≠tve

```bash
# Modell telep√≠t√©se
ollama pull llama3.1:8b

# Ellen≈ërz√©s
ollama list
```

### Python f√ºgg≈ës√©gek hi√°nyoznak

```bash
# F√ºgg≈ës√©gek telep√≠t√©se
pip3 install -r installers/requirements.txt

# Ha hiba van, pr√≥b√°ld:
pip3 install --upgrade pip
pip3 install -r installers/requirements.txt --force-reinstall
```

### Port m√°r haszn√°latban

```bash
# Melyik process haszn√°lja a 8000-es portot?
sudo lsof -i :8000

# Vagy
sudo netstat -tulpn | grep :8000

# Process le√°ll√≠t√°sa (ha sz√ºks√©ges)
sudo kill -9 <PID>
```

### Jogosults√°g hib√°k

```bash
# Scriptek futtathat√≥v√° t√©tele
chmod +x start.sh
chmod +x installers/install.sh

# Mapp√°k jogosults√°gai
chmod -R 755 logs data projects
```

### Log f√°jlok ellen≈ërz√©se

```bash
# Alkalmaz√°s logok
tail -f logs/app.log

# Ollama logok
tail -f logs/ollama.log

# Hib√°k keres√©se
grep -i error logs/app.log
```

---

## üìù Tov√°bbi inform√°ci√≥k

- **API dokument√°ci√≥**: http://localhost:8000/docs
- **Projekt strukt√∫ra**: `docs/PROJECT_STRUCTURE.md`
- **Haszn√°lati √∫tmutat√≥**: `docs/USAGE_GUIDE.md`
- **GitHub repository**: https://github.com/zedinke/ZedinArkManager

---

## üéâ Sikeres telep√≠t√©s!

Ha minden l√©p√©s sikeres volt, a rendszer most fut √©s haszn√°latra k√©sz!

**Els≈ë l√©p√©sek:**
1. Nyisd meg: http://localhost:8000/docs
2. Pr√≥b√°ld ki a `/api/chat` endpoint-ot
3. Gener√°lj k√≥dot a `/api/generate` endpoint-tal

**J√≥ munk√°t! üöÄ**

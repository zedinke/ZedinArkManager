# ‚ö° Teljes√≠tm√©ny optimaliz√°l√°s

## üêå Lass√∫ v√°laszid≈ë probl√©m√°k

Ha a chat API v√°lasza t√∂bb mint 60 m√°sodperc, ez t√∂bb okb√≥l lehet:

### 1. LLM v√°lasz gener√°l√°s ideje (norm√°lis)

Az LLM modellek v√°lasz gener√°l√°sa **t√∂bb m√°sodpercig is eltarthat**, ez norm√°lis:

**V√°laszid≈ë √°ltal√°ban:**
- **phi3:mini** (3B): 2-5 m√°sodperc
- **llama3.1:8b**: 5-15 m√°sodperc
- **mistral:7b**: 5-15 m√°sodperc
- **codellama:7b**: 8-20 m√°sodperc
- **codellama:13b**: 15-30 m√°sodperc
- **codellama:34b**: 30-90 m√°sodperc
- **llama3.1:70b**: 60-180+ m√°sodperc

## ‚úÖ Optimaliz√°ci√≥s lehet≈ës√©gek

### 1. Kisebb modell haszn√°lata

**A kisebb modellek sokkal gyorsabbak:**

```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -H "X-API-Key: $API_KEY" \
  -d '{
    "messages": [{"role": "user", "content": "Hello!"}],
    "model": "phi3:mini"
  }'
```

**Gyors modellek (aj√°nlott):**
- `phi3:mini` - Nagyon gyors, kisebb v√°laszokhoz t√∂k√©letes
- `llama3.1:8b` - Gyors, j√≥ min≈ës√©g
- `mistral:7b` - Gyors, j√≥ min≈ës√©g

### 2. Stream haszn√°lata (val√≥s idej≈± v√°lasz)

**A stream endpoint azonnal kezdi mutatni a v√°laszt:**

```bash
curl -X POST http://localhost:8000/api/chat/stream \
  -H "Content-Type: application/json" \
  -H "X-API-Key: $API_KEY" \
  -d '{
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```

**Python p√©lda streamhez:**
```python
import requests

response = requests.post(
    "http://localhost:8000/api/chat/stream",
    headers={"X-API-Key": "your-api-key"},
    json={"messages": [{"role": "user", "content": "Hello!"}]},
    stream=True
)

for line in response.iter_lines():
    if line:
        print(line.decode('utf-8'))
```

### 3. R√∂videbb prompt

**R√∂videbb prompt = gyorsabb v√°lasz:**

```bash
# Lassabb (hossz√∫ prompt)
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -H "X-API-Key: $API_KEY" \
  -d '{
    "messages": [{"role": "user", "content": "Write a detailed explanation about how artificial intelligence works, including machine learning, neural networks, and deep learning concepts."}]
  }'

# Gyorsabb (r√∂vid prompt)
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -H "X-API-Key: $API_KEY" \
  -d '{
    "messages": [{"role": "user", "content": "Hi"}]
  }'
```

### 4. Temperature cs√∂kkent√©se

**Alacsonyabb temperature = gyorsabb, konzisztensebb v√°lasz:**

```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -H "X-API-Key: $API_KEY" \
  -d '{
    "messages": [{"role": "user", "content": "Hello!"}],
    "temperature": 0.3
  }'
```

### 5. GPU haszn√°lata

**Ha van GPU, akkor sokkal gyorsabb:**

```bash
# GPU √°llapot ellen≈ërz√©se
curl http://localhost:8000/api/gpu/status

# Ha GPU van, automatikusan haszn√°lja
```

**GPU be√°ll√≠t√°sa (.env f√°jlban):**
```env
OLLAMA_NUM_GPU_LAYERS=35
```

### 6. Ollama optimaliz√°l√°s

**Ollama be√°ll√≠t√°sok optimaliz√°l√°sa:**

```env
# .env f√°jl
OLLAMA_NUM_THREADS=32  # CPU sz√°lak sz√°ma
OLLAMA_NUM_GPU_LAYERS=35  # GPU r√©tegek sz√°ma
```

### 7. Timeout n√∂vel√©se

**Ha nagy modellt haszn√°lsz, n√∂veld a timeout-ot:**

```bash
# 180 m√°sodperces timeout (3 perc)
curl --max-time 180 -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -H "X-API-Key: $API_KEY" \
  -d '{
    "messages": [{"role": "user", "content": "Hello!"}],
    "model": "llama3.1:70b"
  }'
```

## üîß Tesztel√©s √©s m√©r√©s

### Gyors teszt (phi3:mini)

```bash
time curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -H "X-API-Key: $API_KEY" \
  -d '{
    "messages": [{"role": "user", "content": "Hi"}],
    "model": "phi3:mini"
  }'
```

### K√∂zepes teszt (llama3.1:8b)

```bash
time curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -H "X-API-Key: $API_KEY" \
  -d '{
    "messages": [{"role": "user", "content": "Hello!"}],
    "model": "llama3.1:8b"
  }'
```

## üìä Teljes√≠tm√©ny √∂sszehasonl√≠t√°s

**V√°rhat√≥ v√°laszid≈ëk (CPU-n, r√∂vid prompt):**

| Modell | V√°laszid≈ë | Haszn√°lat |
|--------|-----------|-----------|
| phi3:mini | 2-5 sec | Gyors v√°laszok |
| llama3.1:8b | 5-15 sec | √Åltal√°nos haszn√°lat |
| mistral:7b | 5-15 sec | √Åltal√°nos haszn√°lat |
| codellama:7b | 8-20 sec | K√≥d gener√°l√°s |
| codellama:13b | 15-30 sec | Komplex k√≥d |
| codellama:34b | 30-90 sec | Nagyon komplex k√≥d |
| llama3.1:70b | 60-180+ sec | Legjobb min≈ës√©g |

**GPU-val 2-5x gyorsabb lehet!**

## ‚úÖ Aj√°nl√°sok

### Gyors v√°laszokhoz:

1. ‚úÖ **Haszn√°lj kisebb modellt** (`phi3:mini` vagy `llama3.1:8b`)
2. ‚úÖ **R√∂vid prompt** haszn√°lata
3. ‚úÖ **Stream endpoint** haszn√°lata (val√≥s idej≈± v√°lasz)
4. ‚úÖ **Alacsonyabb temperature** (0.3-0.5)

### Jobb min≈ës√©ghez (ha id≈ë nem sz√°m√≠t):

1. ‚úÖ **Nagyobb modell** haszn√°lata (`codellama:34b` vagy `llama3.1:70b`)
2. ‚úÖ **Nagyobb timeout** (180+ m√°sodperc)
3. ‚úÖ **GPU haszn√°lata** (ha van)

### K√≥d gener√°l√°shoz:

1. ‚úÖ **Codellama modellek** (`codellama:7b`, `codellama:13b`, `codellama:34b`)
2. ‚úÖ **Stream haszn√°lata** (val√≥s idej≈± l√°t√°s)
3. ‚úÖ **R√©szletes prompt**

## üöÄ Gyors p√©lda

**Optim√°lis be√°ll√≠t√°s gyors v√°laszhoz:**
```bash
export API_KEY="your-api-key-here"

curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -H "X-API-Key: $API_KEY" \
  -d '{
    "messages": [{"role": "user", "content": "Hello!"}],
    "model": "phi3:mini",
    "temperature": 0.5
  }'
```

**Vagy stream (val√≥s idej≈±):**
```bash
curl -X POST http://localhost:8000/api/chat/stream \
  -H "Content-Type: application/json" \
  -H "X-API-Key: $API_KEY" \
  -d '{
    "messages": [{"role": "user", "content": "Hello!"}],
    "model": "phi3:mini"
  }'
```

---

**Most m√°r gyorsabban m≈±k√∂dik! ‚ö°**


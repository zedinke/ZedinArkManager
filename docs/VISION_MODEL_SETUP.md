# üñºÔ∏è Vision Model Telep√≠t√©si √ötmutat√≥

## üéØ C√©l

A vision model lehet≈ëv√© teszi, hogy az AI **l√°ssa √©s √©rtelmezze a k√©peket**. A rendszer Ollama vision modelleket haszn√°l (pl. llava).

## üì¶ Telep√≠t√©s

### 1. Vision Model Let√∂lt√©se

Telep√≠tsd a llava vision modelt:

```bash
ollama pull llava
```

Vagy m√°s vision modelleket:

```bash
# Kisebb, gyorsabb modell
ollama pull llava:7b

# Nagyobb, pontosabb modell
ollama pull llava:13b
ollama pull llava:34b
```

### 2. Ellen≈ërz√©s

Ellen≈ërizd, hogy a modell telep√≠tve van-e:

```bash
ollama list
```

Keress r√°: `llava` a list√°ban.

## üöÄ Haszn√°lat

### VS Code Extension-ben

1. **K√©p felt√∂lt√©se:**
   - Nyisd meg a ZedinArk AI sidebar chat-et
   - Kattints a **"K√©p"** gombra
   - V√°laszd ki a k√©pet

2. **K√©p elemz√©se:**
   - A k√©p automatikusan felt√∂lt≈ëdik
   - Az AI elemzi a k√©pet √©s le√≠rja, mit l√°t

### API-n kereszt√ºl

```bash
# K√©p base64 k√≥dol√°sa (Linux/Mac)
IMAGE_B64=$(base64 -i image.jpg)

# API h√≠v√°s
curl -X POST http://localhost:8000/api/vision \
  -H "Content-Type: application/json" \
  -H "X-API-Key: YOUR_API_KEY" \
  -d "{
    \"image\": \"$IMAGE_B64\",
    \"prompt\": \"Elemezd ezt a k√©pet r√©szletesen\",
    \"model\": \"llava\"
  }"
```

## ‚öôÔ∏è Konfigur√°ci√≥

### Modell megad√°sa

A vision endpoint automatikusan a `llava` modellt haszn√°lja. M√°s modellt is megadhatsz:

```json
{
  "image": "base64_encoded_image",
  "prompt": "Elemezd ezt a k√©pet",
  "model": "llava:13b"
}
```

### Alap√©rtelmezett prompt

Ha nem adsz meg promptot, az alap√©rtelmezett prompt haszn√°latos:
> "Elemezd ezt a k√©pet r√©szletesen. √çrd le, mit l√°tsz, milyen objektumok, sz√≠nek, sz√∂vegek vannak rajta, √©s adj relev√°ns inform√°ci√≥kat."

## üêõ Hibaelh√°r√≠t√°s

### "Vision model nincs telep√≠tve" hiba

**Probl√©ma:** `Vision model (llava) nincs telep√≠tve`

**Megold√°s:**
```bash
ollama pull llava
```

### "Ollama API nem el√©rhet≈ë" hiba

**Probl√©ma:** `Ollama vision API nem el√©rhet≈ë`

**Megold√°s:**
1. Ellen≈ërizd, hogy Ollama fut-e:
   ```bash
   curl http://localhost:11434/api/tags
   ```

2. Ind√≠tsd el Ollama-t:
   ```bash
   ollama serve
   ```

### Lass√∫ v√°laszok

**Probl√©ma:** A vision elemz√©s lass√∫

**Megold√°sok:**
1. Haszn√°lj kisebb modellt (pl. `llava:7b` helyett `llava:13b`)
2. Cs√∂kkentsd a k√©p m√©ret√©t a felt√∂lt√©s el≈ëtt
3. Gyorsabb GPU-val dolgozz

## üìä T√°mogatott modellek

- **llava** - √Åltal√°nos c√©l√∫ vision model (alap√©rtelmezett)
- **llava:7b** - Kisebb, gyorsabb verzi√≥
- **llava:13b** - K√∂zepes, pontosabb verzi√≥
- **llava:34b** - Nagy, nagyon pontos verzi√≥ (sok mem√≥ria)

## üí° Tippek

1. **K√©p m√©rete:** A kisebb k√©pek gyorsabban feldolgozhat√≥k. Javasolt max. 1024x1024 pixel.

2. **K√©p form√°tum:** A legt√∂bb form√°tum t√°mogatott (JPEG, PNG, etc.), de a JPEG √°ltal√°ban a leghat√©konyabb.

3. **Batch feldolgoz√°s:** Jelenleg egy k√©pet lehet egyszerre elemezni. A t√∂bbsz√∂r√∂s k√©p elemz√©shez k√ºl√∂n k√©r√©seket kell k√ºldeni.

4. **Context:** A vision model nagyobb context window-ot haszn√°l (4096 token), √≠gy r√©szletesebb elemz√©seket tud k√©sz√≠teni.

---

**Most m√°r az AI l√°thatja √©s √©rtelmezheti a k√©peket! üéâ**


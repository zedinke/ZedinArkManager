"""
Distributed Computing Network - K√∂z√∂s er≈ëforr√°s haszn√°lat
Minden felhaszn√°l√≥ er≈ëforr√°sait (GPU, CPU) k√∂z√∂sen haszn√°lja a rendszer
"""
import asyncio
import logging
from typing import List, Dict, Optional, Tuple, Any
import random
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from enum import Enum
import uuid
import requests
import aiohttp
from concurrent.futures import ThreadPoolExecutor, as_completed

logger = logging.getLogger(__name__)


class NodeStatus(str, Enum):
    """Csom√≥pont √°llapot"""
    ONLINE = "online"
    OFFLINE = "offline"
    BUSY = "busy"
    ERROR = "error"


@dataclass
class ComputeNode:
    """Sz√°m√≠t√°si csom√≥pont (felhaszn√°l√≥ g√©p)"""
    node_id: str
    user_id: str
    name: str
    ollama_url: str
    api_key: Optional[str] = None
    status: NodeStatus = NodeStatus.OFFLINE
    gpu_count: int = 0
    gpu_memory: int = 0  # MB
    cpu_cores: int = 0
    available_models: List[str] = field(default_factory=list)
    current_load: float = 0.0  # 0.0 - 1.0
    last_seen: datetime = field(default_factory=datetime.now)
    response_time: float = 0.0  # ms
    total_requests: int = 0
    successful_requests: int = 0
    
    def is_available(self, max_age_seconds: int = 600) -> bool:
        """Ellen≈ërzi, hogy el√©rhet≈ë-e a csom√≥pont (10 perc offline timeout)"""
        # Ha ERROR st√°tuszban van, nem el√©rhet≈ë
        if self.status == NodeStatus.ERROR:
            return False
        # Ha ONLINE vagy BUSY, akkor el√©rhet≈ë (BUSY = ideiglenesen nem el√©rhet≈ë, de ne t√°vol√≠tsuk el)
        if self.status == NodeStatus.ONLINE or self.status == NodeStatus.BUSY:
            age = (datetime.now() - self.last_seen).total_seconds()
            return age < max_age_seconds and self.current_load < 0.9
        # Ha OFFLINE, akkor csak akkor el√©rhet≈ë, ha nem r√©gen volt akt√≠v
        if self.status == NodeStatus.OFFLINE:
            age = (datetime.now() - self.last_seen).total_seconds()
            return age < max_age_seconds
        return False


@dataclass
class DistributedTask:
    """Elosztott feladat"""
    task_id: str
    user_id: str
    model: str
    messages: List[Dict[str, str]]
    assigned_nodes: List[str] = field(default_factory=list)
    results: Dict[str, Any] = field(default_factory=dict)
    status: str = "pending"  # pending, processing, completed, failed
    created_at: datetime = field(default_factory=datetime.now)
    completed_at: Optional[datetime] = None


class DistributedComputingNetwork:
    """Elosztott sz√°m√≠t√°si h√°l√≥zat koordin√°tor"""
    
    def __init__(self):
        self.nodes: Dict[str, ComputeNode] = {}
        self.tasks: Dict[str, DistributedTask] = {}
        self.executor = ThreadPoolExecutor(max_workers=50)
        self.lock = asyncio.Lock()
        # Connection pool optimaliz√°ci√≥: √∫jrahasznos√≠tott HTTP session-√∂k
        self._session_pool: Optional[aiohttp.ClientSession] = None
        # Round-robin load balancing: k√∂vetkez≈ë node index
        self._load_balance_index = 0
    
    def register_node(self, node_id: str, user_id: str, name: str, 
                     ollama_url: str, api_key: Optional[str] = None,
                     gpu_count: int = 0, gpu_memory: int = 0, 
                     cpu_cores: int = 0) -> ComputeNode:
        """Csom√≥pont regisztr√°l√°sa vagy friss√≠t√©se"""
        # Ha a node m√°r l√©tezik, friss√≠ts√ºk (pl. √∫jraregisztr√°ci√≥ timeout ut√°n)
        if node_id in self.nodes:
            existing_node = self.nodes[node_id]
            # Friss√≠ts√ºk a last_seen-t √©s √°ll√≠tsuk ONLINE-ra (ha BUSY volt)
            existing_node.last_seen = datetime.now()
            if existing_node.status == NodeStatus.BUSY:
                existing_node.status = NodeStatus.ONLINE
                logger.info(f"üîÑ Node re-registered (was BUSY): {node_id} ({name}) from {ollama_url}")
            else:
                logger.info(f"üîÑ Node re-registered: {node_id} ({name}) from {ollama_url}")
            # Friss√≠ts√ºk az adatokat is, ha v√°ltoztak
            existing_node.ollama_url = ollama_url
            existing_node.gpu_count = gpu_count
            existing_node.gpu_memory = gpu_memory
            existing_node.cpu_cores = cpu_cores
            return existing_node
        
        # √öj node regisztr√°l√°sa
        node = ComputeNode(
            node_id=node_id,
            user_id=user_id,
            name=name,
            ollama_url=ollama_url,
            api_key=api_key,
            gpu_count=gpu_count,
            gpu_memory=gpu_memory,
            cpu_cores=cpu_cores,
            status=NodeStatus.ONLINE,
            last_seen=datetime.now()
        )
        self.nodes[node_id] = node
        logger.info(f"Node registered: {node_id} ({name}) from {ollama_url}")
        return node
    
    def update_node_status(self, node_id: str, status: NodeStatus,
                          available_models: Optional[List[str]] = None,
                          current_load: Optional[float] = None,
                          response_time: Optional[float] = None):
        """Csom√≥pont √°llapot friss√≠t√©se"""
        if node_id in self.nodes:
            node = self.nodes[node_id]
            node.status = status
            node.last_seen = datetime.now()
            if available_models is not None:
                node.available_models = available_models
            if current_load is not None:
                node.current_load = current_load
            if response_time is not None:
                node.response_time = response_time
    
    def get_available_nodes(self, model: Optional[str] = None, 
                          min_gpu_memory: int = 0,
                          ignore_model_filter: bool = False) -> List[ComputeNode]:
        """
        El√©rhet≈ë csom√≥pontok lek√©r√©se
        
        Args:
            model: Modell neve (opcion√°lis sz≈±r√©shez)
            min_gpu_memory: Minim√°lis GPU mem√≥ria (MB)
            ignore_model_filter: Ha True, minden el√©rhet≈ë csom√≥pontot visszaad, f√ºggetlen√ºl a modellt≈ël
        """
        available = []
        for node in self.nodes.values():
            # Ellen≈ërizz√ºk az el√©rhet≈ës√©get (de a szerver node-ot mindig haszn√°ljuk, ha online)
            is_server_node = node.node_id.startswith('server-')
            
            # Ha nem szerver node
            if not is_server_node:
                # ERROR st√°tuszban l√©v≈ë node-ot kihagyjuk
                if node.status == NodeStatus.ERROR:
                    logger.debug(f"‚è≠Ô∏è Skipping ERROR node: {node.node_id}")
                    continue
                # BUSY node-okat is haszn√°ljuk (lehet, hogy most m√°r el√©rhet≈ë)
                elif node.status == NodeStatus.BUSY:
                    # BUSY node-okat is hozz√°adjuk, de csak akkor, ha nem r√©gen volt akt√≠v (15 perc - n√∂velve)
                    age = (datetime.now() - node.last_seen).total_seconds()
                    if age < 900:  # 15 perc (n√∂velve, hogy ne legyen kihagyva)
                        logger.info(f"üîÑ Including BUSY node: {node.node_id} ({node.name}) - will retry (age: {age:.1f}s)")
                        # Folytatjuk, hozz√°adjuk a list√°hoz
                    else:
                        # Ha t√∫l r√©gen volt akt√≠v, kihagyjuk
                        logger.debug(f"‚è≠Ô∏è Skipping BUSY node: {node.node_id} (too old: {age:.1f}s)")
                        continue
                # ONLINE node-okat ellen≈ërizz√ºk
                elif node.status == NodeStatus.ONLINE:
                    # ONLINE node-okat csak akkor haszn√°ljuk, ha el√©rhet≈ë
                    if not node.is_available():
                        logger.debug(f"‚è≠Ô∏è Skipping ONLINE node: {node.node_id} (not available)")
                        continue
                # OFFLINE node-okat csak akkor haszn√°ljuk, ha nem r√©gen volt akt√≠v
                elif node.status == NodeStatus.OFFLINE:
                    age = (datetime.now() - node.last_seen).total_seconds()
                    if age >= 900:  # 15 perc
                        logger.debug(f"‚è≠Ô∏è Skipping OFFLINE node: {node.node_id} (too old: {age:.1f}s)")
                        continue
                    else:
                        logger.info(f"üîÑ Including OFFLINE node: {node.node_id} ({node.name}) - will try (age: {age:.1f}s)")
                else:
                    # Ismeretlen st√°tusz, kihagyjuk
                    logger.debug(f"‚è≠Ô∏è Skipping node with unknown status: {node.node_id} (status: {node.status})")
                    continue
            
            # Ha szerver node, akkor csak az ONLINE st√°tuszt ellen≈ërizz√ºk
            if is_server_node and node.status != NodeStatus.ONLINE:
                continue
                
            if min_gpu_memory > 0 and node.gpu_memory < min_gpu_memory:
                continue
            # Modell sz≈±r√©s csak akkor, ha ignore_model_filter=False
            if not ignore_model_filter and model and model not in node.available_models:
                continue
            available.append(node)
        
        # Rendez√©s: kev√©sb√© terhelt, gyorsabb v√°laszid≈ë
        # DE: Load balancing eset√©n ne rendezz√ºnk, hogy a v√©letlenszer≈± v√°laszt√°s m≈±k√∂dj√∂n
        # Csak akkor rendezz√ºnk, ha nincs load balancing
        # available.sort(key=lambda n: (n.current_load, n.response_time))
        return available
    
    async def distribute_task(self, user_id: str, model: str, 
                             messages: List[Dict[str, str]],
                             use_all_nodes: bool = True,
                             load_balance: bool = True) -> str:
        """
        Feladat eloszt√°sa minden el√©rhet≈ë csom√≥pontra
        
        Args:
            user_id: Felhaszn√°l√≥ ID
            model: Modell neve
            messages: Chat √ºzenetek
            use_all_nodes: Ha True, minden el√©rhet≈ë csom√≥pontot haszn√°l
            load_balance: Ha True, 50-50% terhel√©seloszt√°s (egy node-ot v√°laszt v√©letlenszer≈±en)
        
        Returns:
            Kombin√°lt v√°lasz vagy egy node v√°lasza
        """
        task_id = str(uuid.uuid4())
        task = DistributedTask(
            task_id=task_id,
            user_id=user_id,
            model=model,
            messages=messages,
            status="processing"
        )
        self.tasks[task_id] = task
        
        # El√©rhet≈ë csom√≥pontok keres√©se
        # ignore_model_filter=True: minden modell haszn√°lja az √∂sszes beregisztr√°lt er≈ëforr√°st
        available_nodes = self.get_available_nodes(model=model, ignore_model_filter=True)
        
        # Logol√°s: mely node-ok vannak el√©rhet≈ë
        if available_nodes:
            node_list = [f"{n.node_id} ({n.name}) [{n.status.value}]" for n in available_nodes]
            logger.info(f"üìã Available nodes for task: {node_list}")
        else:
            # Ha nincs el√©rhet≈ë node, logoljuk az √∂sszes regisztr√°lt node-ot
            all_nodes = [f"{n.node_id} ({n.name}) [{n.status.value}]" for n in self.nodes.values()]
            logger.warning(f"‚ö†Ô∏è No available nodes! All registered nodes: {all_nodes}")
            task.status = "failed"
            raise Exception("No available compute nodes")
        
        # P√°rhuzamos m√≥d: minden k√©r√©sn√©l MINDK√âT node-ot haszn√°ljuk
        if use_all_nodes and len(available_nodes) >= 2:
            # Mindk√©t node-ot haszn√°ljuk p√°rhuzamosan
            logger.info(f"üöÄ Parallel mode: Using ALL {len(available_nodes)} nodes simultaneously: {[n.node_id for n in available_nodes]}")
        elif load_balance and len(available_nodes) >= 2:
            # Round-robin: felv√°ltva v√°lasztunk (50-50% garant√°lt)
            # Ez csak akkor haszn√°latos, ha use_all_nodes=False
            selected_index = self._load_balance_index % len(available_nodes)
            selected_node = available_nodes[selected_index]
            self._load_balance_index += 1
            available_nodes = [selected_node]
            
            # Logol√°s: mely node-ok voltak el√©rhet≈ëk
            all_node_ids = [n.node_id for n in available_nodes]
            logger.info(f"‚öñÔ∏è Load balancing (round-robin): Selected node {selected_node.node_id} ({selected_node.name}) - index {selected_index}/{len(available_nodes)-1} from {len(all_node_ids)} available nodes")
        elif not use_all_nodes:
            # Ha use_all_nodes=False, csak a legjobb csom√≥pontot haszn√°ljuk
            available_nodes = available_nodes[:1]
        
        logger.info(f"Distributing task {task_id} to {len(available_nodes)} nodes: {[n.node_id for n in available_nodes]}")
        
        # P√°rhuzamos k√©r√©sek minden csom√≥pontra (bele√©rtve a szerver node-ot is)
        futures = []
        for node in available_nodes:
            task.assigned_nodes.append(node.node_id)
            logger.info(f"Creating async task for node: {node.node_id} ({node.name})")
            future = asyncio.create_task(
                self._execute_on_node(node, model, messages)
            )
            futures.append((node.node_id, future))
        
        # V√°laszok gy≈±jt√©se - OPTIMALIZ√ÅLT: els≈ë v√°lasz visszaad√°sa
        results = {}
        errors = {}
        
        # Ha csak egy node van, nincs sz√ºks√©g p√°rhuzamos v√°rakoz√°sra
        if len(futures) == 1:
            node_id, future = futures[0]
            try:
                result = await asyncio.wait_for(future, timeout=300)  # 5 perc timeout
                results[node_id] = result
                if node_id in self.nodes:
                    self.nodes[node_id].total_requests += 1
                    self.nodes[node_id].successful_requests += 1
                logger.info(f"‚úÖ Node {node_id} responded successfully")
                task.results = results
                task.status = "completed"
                task.completed_at = datetime.now()
                return result  # Azonnal visszaadjuk, nincs sz√ºks√©g kombin√°l√°sra
            except Exception as e:
                error_msg = str(e)
                logger.error(f"‚ùå Node {node_id} error: {error_msg}")
                raise Exception(f"Node {node_id} failed: {error_msg}")
        
        # T√∂bb node eset√©n: V√ÅRJUNK MINDK√âT V√ÅLASZRA √©s kombin√°ljuk
        # Ez biztos√≠tja, hogy mindk√©t er≈ëforr√°s val√≥ban haszn√°lva legyen
        logger.info(f"‚è≥ Waiting for responses from {len(futures)} nodes (parallel processing)...")
        
        # V√°rakoz√°s MINDK√âT v√°laszra (p√°rhuzamos feldolgoz√°s)
        for node_id, future in futures:
            try:
                result = await asyncio.wait_for(future, timeout=300)  # 5 perc timeout
                results[node_id] = result
                if node_id in self.nodes:
                    self.nodes[node_id].total_requests += 1
                    self.nodes[node_id].successful_requests += 1
                logger.info(f"‚úÖ Node {node_id} responded successfully")
            except asyncio.TimeoutError:
                errors[node_id] = "Timeout (300s)"
                logger.warning(f"‚è±Ô∏è Node {node_id} timeout: No response within 300 seconds")
                if node_id in self.nodes:
                    self.nodes[node_id].total_requests += 1
                    self.update_node_status(node_id, NodeStatus.BUSY)
            except Exception as e:
                error_msg = str(e)
                errors[node_id] = error_msg
                logger.warning(f"‚ö†Ô∏è Node {node_id} error: {error_msg}")
                if node_id in self.nodes:
                    self.nodes[node_id].total_requests += 1
                    # Csak akkor √°ll√≠tsuk ERROR-ra, ha val√≥di hiba van (nem timeout/connection)
                    if "timeout" not in error_msg.lower() and "connection" not in error_msg.lower():
                        self.update_node_status(node_id, NodeStatus.ERROR)
                    else:
                        self.update_node_status(node_id, NodeStatus.BUSY)
        
        task.results = results
        task.status = "completed" if results else "failed"
        task.completed_at = datetime.now()
        
        # V√°lasz visszaad√°sa
        if results:
            # Ha t√∂bb v√°lasz van, kombin√°ljuk, k√ºl√∂nben az els≈ët haszn√°ljuk
            if len(results) > 1:
                combined_response = self._combine_responses(list(results.values()))
                logger.info(f"Task {task_id} completed: {len(results)}/{len(available_nodes)} successful (combined)")
                if errors:
                    failed_nodes = list(errors.keys())
                    logger.debug(f"‚ö†Ô∏è Some nodes failed ({len(errors)}/{len(available_nodes)}): {failed_nodes}")
                return combined_response
            else:
                # Csak egy v√°lasz van, azonnal visszaadjuk
                logger.info(f"Task {task_id} completed: {len(results)}/{len(available_nodes)} successful (single response)")
                return first_result
        else:
            logger.error(f"‚ùå All nodes failed for task {task_id}: {errors}")
            raise Exception(f"All nodes failed: {errors}")
    
    async def _execute_on_node(self, node: ComputeNode, model: str,
                              messages: List[Dict[str, str]], retry_count: int = 0) -> str:
        """Feladat v√©grehajt√°sa egy csom√≥ponton - ASZINKRON HTTP k√©r√©s RETRY logik√°val"""
        start_time = datetime.now()
        max_retries = 2  # Maximum 2 √∫jrapr√≥b√°l√°s
        retry_delay = 2  # 2 m√°sodperc v√°rakoz√°s az √∫jrapr√≥b√°l√°sok k√∂z√∂tt
        
        logger.info(f"üöÄ Executing task on node: {node.node_id} ({node.name}) at {node.ollama_url} (attempt {retry_count + 1}/{max_retries + 1})")
        
        try:
            # Ollama API h√≠v√°s - MINDEN node-nak HTTP k√©r√©st k√ºld√ºnk, m√©g a szerver node-nak is
            # ASZINKRON k√©r√©s haszn√°lata - ez biztos√≠tja, hogy p√°rhuzamosan fut √©s val√≥ban haszn√°lja az er≈ëforr√°sokat
            url = f"{node.ollama_url}/api/chat"
            payload = {
                "model": model,
                "messages": messages,
                "stream": False
            }
            
            headers = {"Content-Type": "application/json"}
            if node.api_key:
                headers["X-API-Key"] = node.api_key
            
            # Aszinkron HTTP k√©r√©s - ez biztos√≠tja a val√≥di p√°rhuzamos futtat√°st
            # FONTOS: Az Ollama automatikusan haszn√°lja a GPU-t, ha el√©rhet≈ë
            # Nem kell k√ºl√∂n GPU opci√≥kat be√°ll√≠tani, az Ollama detekt√°lja
            # OPTIMALIZ√ÅLT: Connection pooling √©s keep-alive haszn√°lata
            if self._session_pool is None or self._session_pool.closed:
                connector = aiohttp.TCPConnector(limit=100, limit_per_host=10, keepalive_timeout=30)
                self._session_pool = aiohttp.ClientSession(connector=connector)
            
            session = self._session_pool
            logger.debug(f"üì° Sending async HTTP request to {url} for node {node.node_id}")
            logger.debug(f"   Node GPU info: {node.gpu_count} GPU(s), {node.gpu_memory} MB memory")
            
            try:
                # N√∂velt connect timeout (30 m√°sodperc) - lehet, hogy a node lassan v√°laszol
                async with session.post(url, json=payload, headers=headers, timeout=aiohttp.ClientTimeout(total=300, connect=30)) as response:
                    if response.status == 200:
                        data = await response.json()
                        result = data.get("message", {}).get("content", "") or data.get("response", "")
                        
                        # V√°laszid≈ë m√©r√©se
                        response_time = (datetime.now() - start_time).total_seconds() * 1000
                        logger.info(f"‚úÖ Node {node.node_id} completed in {response_time:.2f}ms, response length: {len(result)} chars")
                        if node.gpu_count > 0:
                            logger.info(f"   üíª GPU used: {node.gpu_count} GPU(s), {node.gpu_memory} MB")
                        self.update_node_status(node.node_id, NodeStatus.ONLINE, 
                                               response_time=response_time)
                        
                        return result
                    else:
                        error_text = await response.text()
                        raise Exception(f"Ollama API error: {response.status} - {error_text}")
            except asyncio.TimeoutError:
                # RETRY logika: ha m√©g nem pr√≥b√°ltuk meg max_retries-szer, pr√≥b√°ljuk √∫jra
                if retry_count < max_retries:
                    logger.warning(f"‚è±Ô∏è Node {node.node_id} timeout (attempt {retry_count + 1}/{max_retries + 1}), retrying in {retry_delay}s...")
                    await asyncio.sleep(retry_delay)
                    # Ne √°ll√≠tsuk ERROR-ra, csak BUSY-ra
                    self.update_node_status(node.node_id, NodeStatus.BUSY)
                    # √öjrapr√≥b√°l√°s
                    return await self._execute_on_node(node, model, messages, retry_count + 1)
                else:
                    logger.error(f"‚ùå Node {node.node_id} timeout after {max_retries + 1} attempts: Could not reach {url}")
                    # Csak akkor √°ll√≠tsuk BUSY-ra, ha minden √∫jrapr√≥b√°l√°s sikertelen volt
                    self.update_node_status(node.node_id, NodeStatus.BUSY)
                    raise Exception(f"Node {node.node_id} timeout: Could not reach Ollama at {url} after {max_retries + 1} attempts")
            except aiohttp.ClientError as e:
                error_msg = str(e)
                # RETRY logika: ha m√©g nem pr√≥b√°ltuk meg max_retries-szer, pr√≥b√°ljuk √∫jra
                if retry_count < max_retries and ("timeout" in error_msg.lower() or "Connection timed out" in error_msg):
                    logger.warning(f"üîå Node {node.node_id} connection timeout (attempt {retry_count + 1}/{max_retries + 1}), retrying in {retry_delay}s...")
                    await asyncio.sleep(retry_delay)
                    # Ne √°ll√≠tsuk ERROR-ra, csak BUSY-ra
                    self.update_node_status(node.node_id, NodeStatus.BUSY)
                    # √öjrapr√≥b√°l√°s
                    return await self._execute_on_node(node, model, messages, retry_count + 1)
                
                logger.error(f"‚ùå Node {node.node_id} connection error: {e}")
                # Ne √°ll√≠tsuk ERROR-ra, csak BUSY-ra (lehet, hogy ideiglenes probl√©ma)
                self.update_node_status(node.node_id, NodeStatus.BUSY)
                raise Exception(f"Node {node.node_id} connection error: {e}")
        
        except Exception as e:
            # Csak akkor √°ll√≠tsuk ERROR-ra, ha val√≥di hiba van (nem timeout/connection)
            error_msg = str(e)
            if "timeout" not in error_msg.lower() and "connection" not in error_msg.lower():
                logger.error(f"‚ùå Node {node.node_id} error: {e}")
                self.update_node_status(node.node_id, NodeStatus.ERROR)
            else:
                logger.warning(f"‚ö†Ô∏è Node {node.node_id} connection/timeout error: {e}")
                self.update_node_status(node.node_id, NodeStatus.BUSY)
            raise
    
    def _combine_responses(self, responses: List[str]) -> str:
        """T√∂bb v√°lasz kombin√°l√°sa intelligensen"""
        if not responses:
            return ""
        
        if len(responses) == 1:
            return responses[0]
        
        # Ha minden v√°lasz megegyezik, csak egyet adunk vissza
        if len(set(responses)) == 1:
            return responses[0]
        
        # V√°laszok hossza alapj√°n rendez√©s (hosszabb = r√©szletesebb)
        responses_sorted = sorted(responses, key=len, reverse=True)
        
        # Legr√©szletesebb v√°lasz + egyedi inform√°ci√≥k a t√∂bbib≈ël
        combined = responses_sorted[0]
        
        # √öj inform√°ci√≥k keres√©se a t√∂bbi v√°laszban
        base_words = set(responses_sorted[0].lower().split())
        
        for response in responses_sorted[1:]:
            response_words = set(response.lower().split())
            new_words = response_words - base_words
            
            # Ha van jelent≈ës √∫j inform√°ci√≥ (t√∂bb mint 10 egyedi sz√≥)
            if len(new_words) > 10:
                combined += f"\n\n--- Tov√°bbi inform√°ci√≥ m√°sik csom√≥pontr√≥l ---\n\n{response}"
        
        return combined
    
    def get_network_stats(self) -> Dict[str, Any]:
        """H√°l√≥zat statisztik√°k"""
        online_nodes = [n for n in self.nodes.values() if n.status == NodeStatus.ONLINE]
        total_gpu = sum(n.gpu_count for n in online_nodes)
        total_memory = sum(n.gpu_memory for n in online_nodes)
        total_cores = sum(n.cpu_cores for n in online_nodes)
        
        return {
            "total_nodes": len(self.nodes),
            "online_nodes": len(online_nodes),
            "total_gpu": total_gpu,
            "total_gpu_memory_gb": total_memory / 1024,
            "total_cpu_cores": total_cores,
            "active_tasks": len([t for t in self.tasks.values() if t.status == "processing"]),
            "completed_tasks": len([t for t in self.tasks.values() if t.status == "completed"])
        }
    
    def cleanup_old_tasks(self, max_age_hours: int = 24):
        """R√©gi feladatok t√∂rl√©se"""
        cutoff = datetime.now() - timedelta(hours=max_age_hours)
        to_remove = [
            task_id for task_id, task in self.tasks.items()
            if task.completed_at and task.completed_at < cutoff
        ]
        for task_id in to_remove:
            del self.tasks[task_id]
        logger.info(f"Cleaned up {len(to_remove)} old tasks")


# Glob√°lis h√°l√≥zat p√©ld√°ny
distributed_network = DistributedComputingNetwork()


"""
Distributed Computing Network - K√∂z√∂s er≈ëforr√°s haszn√°lat
Minden felhaszn√°l√≥ er≈ëforr√°sait (GPU, CPU) k√∂z√∂sen haszn√°lja a rendszer
"""
import asyncio
import logging
from typing import List, Dict, Optional, Tuple, Any
import random
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from enum import Enum
import uuid
import requests
import aiohttp
from concurrent.futures import ThreadPoolExecutor, as_completed

logger = logging.getLogger(__name__)


class NodeStatus(str, Enum):
    """Csom√≥pont √°llapot"""
    ONLINE = "online"
    OFFLINE = "offline"
    BUSY = "busy"
    ERROR = "error"


@dataclass
class ComputeNode:
    """Sz√°m√≠t√°si csom√≥pont (felhaszn√°l√≥ g√©p)"""
    node_id: str
    user_id: str
    name: str
    ollama_url: str
    api_key: Optional[str] = None
    status: NodeStatus = NodeStatus.OFFLINE
    gpu_count: int = 0
    gpu_memory: int = 0  # MB
    cpu_cores: int = 0
    available_models: List[str] = field(default_factory=list)
    current_load: float = 0.0  # 0.0 - 1.0
    last_seen: datetime = field(default_factory=datetime.now)
    response_time: float = 0.0  # ms
    total_requests: int = 0
    successful_requests: int = 0
    
    def is_available(self, max_age_seconds: int = 600) -> bool:
        """Ellen≈ërzi, hogy el√©rhet≈ë-e a csom√≥pont (10 perc offline timeout)"""
        # Ha ERROR st√°tuszban van, nem el√©rhet≈ë
        if self.status == NodeStatus.ERROR:
            return False
        # Ha ONLINE vagy BUSY, akkor el√©rhet≈ë (BUSY = ideiglenesen nem el√©rhet≈ë, de ne t√°vol√≠tsuk el)
        if self.status == NodeStatus.ONLINE or self.status == NodeStatus.BUSY:
            age = (datetime.now() - self.last_seen).total_seconds()
            return age < max_age_seconds and self.current_load < 0.9
        # Ha OFFLINE, akkor csak akkor el√©rhet≈ë, ha nem r√©gen volt akt√≠v
        if self.status == NodeStatus.OFFLINE:
            age = (datetime.now() - self.last_seen).total_seconds()
            return age < max_age_seconds
        return False


@dataclass
class DistributedTask:
    """Elosztott feladat"""
    task_id: str
    user_id: str
    model: str
    messages: List[Dict[str, str]]
    assigned_nodes: List[str] = field(default_factory=list)
    results: Dict[str, Any] = field(default_factory=dict)
    status: str = "pending"  # pending, processing, completed, failed
    created_at: datetime = field(default_factory=datetime.now)
    completed_at: Optional[datetime] = None


class DistributedComputingNetwork:
    """Elosztott sz√°m√≠t√°si h√°l√≥zat koordin√°tor"""
    
    def __init__(self):
        self.nodes: Dict[str, ComputeNode] = {}
        self.tasks: Dict[str, DistributedTask] = {}
        self.executor = ThreadPoolExecutor(max_workers=50)
        self.lock = asyncio.Lock()
        # Connection pool optimaliz√°ci√≥: √∫jrahasznos√≠tott HTTP session-√∂k
        self._session_pool: Optional[aiohttp.ClientSession] = None
    
    def register_node(self, node_id: str, user_id: str, name: str, 
                     ollama_url: str, api_key: Optional[str] = None,
                     gpu_count: int = 0, gpu_memory: int = 0, 
                     cpu_cores: int = 0) -> ComputeNode:
        """Csom√≥pont regisztr√°l√°sa"""
        node = ComputeNode(
            node_id=node_id,
            user_id=user_id,
            name=name,
            ollama_url=ollama_url,
            api_key=api_key,
            gpu_count=gpu_count,
            gpu_memory=gpu_memory,
            cpu_cores=cpu_cores,
            status=NodeStatus.ONLINE,
            last_seen=datetime.now()
        )
        self.nodes[node_id] = node
        logger.info(f"Node registered: {node_id} ({name}) from {ollama_url}")
        return node
    
    def update_node_status(self, node_id: str, status: NodeStatus,
                          available_models: Optional[List[str]] = None,
                          current_load: Optional[float] = None,
                          response_time: Optional[float] = None):
        """Csom√≥pont √°llapot friss√≠t√©se"""
        if node_id in self.nodes:
            node = self.nodes[node_id]
            node.status = status
            node.last_seen = datetime.now()
            if available_models is not None:
                node.available_models = available_models
            if current_load is not None:
                node.current_load = current_load
            if response_time is not None:
                node.response_time = response_time
    
    def get_available_nodes(self, model: Optional[str] = None, 
                          min_gpu_memory: int = 0,
                          ignore_model_filter: bool = False) -> List[ComputeNode]:
        """
        El√©rhet≈ë csom√≥pontok lek√©r√©se
        
        Args:
            model: Modell neve (opcion√°lis sz≈±r√©shez)
            min_gpu_memory: Minim√°lis GPU mem√≥ria (MB)
            ignore_model_filter: Ha True, minden el√©rhet≈ë csom√≥pontot visszaad, f√ºggetlen√ºl a modellt≈ël
        """
        available = []
        for node in self.nodes.values():
            # Ellen≈ërizz√ºk az el√©rhet≈ës√©get (de a szerver node-ot mindig haszn√°ljuk, ha online)
            is_server_node = node.node_id.startswith('server-')
            
            # Ha nem szerver node
            if not is_server_node:
                # ERROR st√°tuszban l√©v≈ë node-ot kihagyjuk
                if node.status == NodeStatus.ERROR:
                    continue
                # BUSY node-okat is haszn√°ljuk (lehet, hogy most m√°r el√©rhet≈ë)
                elif node.status == NodeStatus.BUSY:
                    # BUSY node-okat is hozz√°adjuk, de csak akkor, ha nem r√©gen volt akt√≠v (10 perc)
                    age = (datetime.now() - node.last_seen).total_seconds()
                    if age < 600:  # 10 perc
                        logger.debug(f"üîÑ Including BUSY node: {node.node_id} (will retry, age: {age:.1f}s)")
                        # Folytatjuk, hozz√°adjuk a list√°hoz
                    else:
                        # Ha t√∫l r√©gen volt akt√≠v, kihagyjuk
                        logger.debug(f"‚è≠Ô∏è Skipping BUSY node: {node.node_id} (too old: {age:.1f}s)")
                        continue
                # ONLINE node-okat ellen≈ërizz√ºk
                elif node.status == NodeStatus.ONLINE:
                    # ONLINE node-okat csak akkor haszn√°ljuk, ha el√©rhet≈ë
                    if not node.is_available():
                        continue
                # OFFLINE node-okat csak akkor haszn√°ljuk, ha nem r√©gen volt akt√≠v
                elif node.status == NodeStatus.OFFLINE:
                    age = (datetime.now() - node.last_seen).total_seconds()
                    if age >= 600:  # 10 perc
                        continue
                else:
                    # Ismeretlen st√°tusz, kihagyjuk
                    continue
            
            # Ha szerver node, akkor csak az ONLINE st√°tuszt ellen≈ërizz√ºk
            if is_server_node and node.status != NodeStatus.ONLINE:
                continue
                
            if min_gpu_memory > 0 and node.gpu_memory < min_gpu_memory:
                continue
            # Modell sz≈±r√©s csak akkor, ha ignore_model_filter=False
            if not ignore_model_filter and model and model not in node.available_models:
                continue
            available.append(node)
        
        # Rendez√©s: kev√©sb√© terhelt, gyorsabb v√°laszid≈ë
        available.sort(key=lambda n: (n.current_load, n.response_time))
        return available
    
    async def distribute_task(self, user_id: str, model: str, 
                             messages: List[Dict[str, str]],
                             use_all_nodes: bool = True,
                             load_balance: bool = True) -> str:
        """
        Feladat eloszt√°sa minden el√©rhet≈ë csom√≥pontra
        
        Args:
            user_id: Felhaszn√°l√≥ ID
            model: Modell neve
            messages: Chat √ºzenetek
            use_all_nodes: Ha True, minden el√©rhet≈ë csom√≥pontot haszn√°l
            load_balance: Ha True, 50-50% terhel√©seloszt√°s (egy node-ot v√°laszt v√©letlenszer≈±en)
        
        Returns:
            Kombin√°lt v√°lasz vagy egy node v√°lasza
        """
        task_id = str(uuid.uuid4())
        task = DistributedTask(
            task_id=task_id,
            user_id=user_id,
            model=model,
            messages=messages,
            status="processing"
        )
        self.tasks[task_id] = task
        
        # El√©rhet≈ë csom√≥pontok keres√©se
        # ignore_model_filter=True: minden modell haszn√°lja az √∂sszes beregisztr√°lt er≈ëforr√°st
        available_nodes = self.get_available_nodes(model=model, ignore_model_filter=True)
        
        if not available_nodes:
            task.status = "failed"
            raise Exception("No available compute nodes")
        
        # Terhel√©seloszt√°s: 50-50% (v√©letlenszer≈±en v√°laszt egy node-ot)
        if load_balance and len(available_nodes) >= 2:
            import random
            # V√©letlenszer≈±en v√°lasztunk egy node-ot (50% es√©ly mindkett≈ëre)
            selected_node = random.choice(available_nodes)
            available_nodes = [selected_node]
            logger.info(f"‚öñÔ∏è Load balancing: Selected node {selected_node.node_id} (50% chance for each node)")
        elif not use_all_nodes:
            # Ha use_all_nodes=False, csak a legjobb csom√≥pontot haszn√°ljuk
            available_nodes = available_nodes[:1]
        
        logger.info(f"Distributing task {task_id} to {len(available_nodes)} nodes: {[n.node_id for n in available_nodes]}")
        
        # P√°rhuzamos k√©r√©sek minden csom√≥pontra (bele√©rtve a szerver node-ot is)
        futures = []
        for node in available_nodes:
            task.assigned_nodes.append(node.node_id)
            logger.info(f"Creating async task for node: {node.node_id} ({node.name})")
            future = asyncio.create_task(
                self._execute_on_node(node, model, messages)
            )
            futures.append((node.node_id, future))
        
        # V√°laszok gy≈±jt√©se - OPTIMALIZ√ÅLT: els≈ë v√°lasz visszaad√°sa
        results = {}
        errors = {}
        
        # Ha csak egy node van, nincs sz√ºks√©g p√°rhuzamos v√°rakoz√°sra
        if len(futures) == 1:
            node_id, future = futures[0]
            try:
                result = await asyncio.wait_for(future, timeout=300)  # 5 perc timeout
                results[node_id] = result
                if node_id in self.nodes:
                    self.nodes[node_id].total_requests += 1
                    self.nodes[node_id].successful_requests += 1
                logger.info(f"‚úÖ Node {node_id} responded successfully")
                task.results = results
                task.status = "completed"
                task.completed_at = datetime.now()
                return result  # Azonnal visszaadjuk, nincs sz√ºks√©g kombin√°l√°sra
            except Exception as e:
                error_msg = str(e)
                logger.error(f"‚ùå Node {node_id} error: {error_msg}")
                raise Exception(f"Node {node_id} failed: {error_msg}")
        
        # T√∂bb node eset√©n: els≈ë v√°lasz visszaad√°sa (gyorsabb)
        # Vagy mindk√©t v√°lasz kombin√°l√°sa, ha mindkett≈ë sikeres
        done, pending = await asyncio.wait(futures, return_when=asyncio.FIRST_COMPLETED)
        
        # Els≈ë sikeres v√°lasz feldolgoz√°sa
        first_result = None
        first_node_id = None
        
        for completed in done:
            node_id, future = [(nid, f) for nid, f in futures if f == completed][0]
            try:
                result = await future
                results[node_id] = result
                first_result = result
                first_node_id = node_id
                if node_id in self.nodes:
                    self.nodes[node_id].total_requests += 1
                    self.nodes[node_id].successful_requests += 1
                logger.info(f"‚úÖ Node {node_id} responded successfully (first)")
                break
            except Exception as e:
                error_msg = str(e)
                errors[node_id] = error_msg
                # Ne √°ll√≠tsuk ERROR-ra azonnal, csak BUSY-ra (lehet, hogy ideiglenes probl√©ma)
                if node_id in self.nodes:
                    # Csak akkor √°ll√≠tsuk ERROR-ra, ha val√≥di hiba van (nem timeout/connection)
                    if "timeout" not in error_msg.lower() and "connection" not in error_msg.lower():
                        self.update_node_status(node_id, NodeStatus.ERROR)
                    else:
                        # Timeout/connection hib√°k eset√©n csak BUSY-ra √°ll√≠tjuk
                        self.update_node_status(node_id, NodeStatus.BUSY)
                logger.warning(f"‚ö†Ô∏è Node {node_id} error: {error_msg}")
        
        # V√°rakoz√°s a t√∂bbi node-ra (ha van), de nem blokkoljuk a v√°laszt
        if pending:
            # V√°rakoz√°s a t√∂bbi node-ra (max 5 m√°sodperc, hogy ne lass√≠tsa)
            remaining_futures = [(nid, f) for nid, f in futures if f in pending]
            for node_id, future in remaining_futures:
                try:
                    result = await asyncio.wait_for(future, timeout=5)  # R√∂videbb timeout a kombin√°l√°shoz
                    results[node_id] = result
                    if node_id in self.nodes:
                        self.nodes[node_id].total_requests += 1
                        self.nodes[node_id].successful_requests += 1
                    logger.info(f"‚úÖ Node {node_id} responded successfully (additional)")
                except asyncio.TimeoutError:
                    errors[node_id] = "Timeout (additional response)"
                    logger.debug(f"‚è±Ô∏è Node {node_id} timeout (additional, not critical)")
                    if node_id in self.nodes:
                        self.nodes[node_id].total_requests += 1
                except Exception as e:
                    error_msg = str(e)
                    errors[node_id] = error_msg
                    logger.debug(f"‚ö†Ô∏è Node {node_id} error (additional): {error_msg}")
                    if node_id in self.nodes:
                        self.nodes[node_id].total_requests += 1
        
        task.results = results
        task.status = "completed" if results else "failed"
        task.completed_at = datetime.now()
        
        # V√°lasz visszaad√°sa
        if results:
            # Ha t√∂bb v√°lasz van, kombin√°ljuk, k√ºl√∂nben az els≈ët haszn√°ljuk
            if len(results) > 1:
                combined_response = self._combine_responses(list(results.values()))
                logger.info(f"Task {task_id} completed: {len(results)}/{len(available_nodes)} successful (combined)")
                if errors:
                    failed_nodes = list(errors.keys())
                    logger.debug(f"‚ö†Ô∏è Some nodes failed ({len(errors)}/{len(available_nodes)}): {failed_nodes}")
                return combined_response
            else:
                # Csak egy v√°lasz van, azonnal visszaadjuk
                logger.info(f"Task {task_id} completed: {len(results)}/{len(available_nodes)} successful (single response)")
                return first_result
        else:
            logger.error(f"‚ùå All nodes failed for task {task_id}: {errors}")
            raise Exception(f"All nodes failed: {errors}")
    
    async def _execute_on_node(self, node: ComputeNode, model: str,
                              messages: List[Dict[str, str]], retry_count: int = 0) -> str:
        """Feladat v√©grehajt√°sa egy csom√≥ponton - ASZINKRON HTTP k√©r√©s RETRY logik√°val"""
        start_time = datetime.now()
        max_retries = 2  # Maximum 2 √∫jrapr√≥b√°l√°s
        retry_delay = 2  # 2 m√°sodperc v√°rakoz√°s az √∫jrapr√≥b√°l√°sok k√∂z√∂tt
        
        logger.info(f"üöÄ Executing task on node: {node.node_id} ({node.name}) at {node.ollama_url} (attempt {retry_count + 1}/{max_retries + 1})")
        
        try:
            # Ollama API h√≠v√°s - MINDEN node-nak HTTP k√©r√©st k√ºld√ºnk, m√©g a szerver node-nak is
            # ASZINKRON k√©r√©s haszn√°lata - ez biztos√≠tja, hogy p√°rhuzamosan fut √©s val√≥ban haszn√°lja az er≈ëforr√°sokat
            url = f"{node.ollama_url}/api/chat"
            payload = {
                "model": model,
                "messages": messages,
                "stream": False
            }
            
            headers = {"Content-Type": "application/json"}
            if node.api_key:
                headers["X-API-Key"] = node.api_key
            
            # Aszinkron HTTP k√©r√©s - ez biztos√≠tja a val√≥di p√°rhuzamos futtat√°st
            # FONTOS: Az Ollama automatikusan haszn√°lja a GPU-t, ha el√©rhet≈ë
            # Nem kell k√ºl√∂n GPU opci√≥kat be√°ll√≠tani, az Ollama detekt√°lja
            # OPTIMALIZ√ÅLT: Connection pooling √©s keep-alive haszn√°lata
            if self._session_pool is None or self._session_pool.closed:
                connector = aiohttp.TCPConnector(limit=100, limit_per_host=10, keepalive_timeout=30)
                self._session_pool = aiohttp.ClientSession(connector=connector)
            
            session = self._session_pool
            logger.debug(f"üì° Sending async HTTP request to {url} for node {node.node_id}")
            logger.debug(f"   Node GPU info: {node.gpu_count} GPU(s), {node.gpu_memory} MB memory")
            
            try:
                # N√∂velt connect timeout (30 m√°sodperc) - lehet, hogy a node lassan v√°laszol
                async with session.post(url, json=payload, headers=headers, timeout=aiohttp.ClientTimeout(total=300, connect=30)) as response:
                    if response.status == 200:
                        data = await response.json()
                        result = data.get("message", {}).get("content", "") or data.get("response", "")
                        
                        # V√°laszid≈ë m√©r√©se
                        response_time = (datetime.now() - start_time).total_seconds() * 1000
                        logger.info(f"‚úÖ Node {node.node_id} completed in {response_time:.2f}ms, response length: {len(result)} chars")
                        if node.gpu_count > 0:
                            logger.info(f"   üíª GPU used: {node.gpu_count} GPU(s), {node.gpu_memory} MB")
                        self.update_node_status(node.node_id, NodeStatus.ONLINE, 
                                               response_time=response_time)
                        
                        return result
                    else:
                        error_text = await response.text()
                        raise Exception(f"Ollama API error: {response.status} - {error_text}")
            except asyncio.TimeoutError:
                # RETRY logika: ha m√©g nem pr√≥b√°ltuk meg max_retries-szer, pr√≥b√°ljuk √∫jra
                if retry_count < max_retries:
                    logger.warning(f"‚è±Ô∏è Node {node.node_id} timeout (attempt {retry_count + 1}/{max_retries + 1}), retrying in {retry_delay}s...")
                    await asyncio.sleep(retry_delay)
                    # Ne √°ll√≠tsuk ERROR-ra, csak BUSY-ra
                    self.update_node_status(node.node_id, NodeStatus.BUSY)
                    # √öjrapr√≥b√°l√°s
                    return await self._execute_on_node(node, model, messages, retry_count + 1)
                else:
                    logger.error(f"‚ùå Node {node.node_id} timeout after {max_retries + 1} attempts: Could not reach {url}")
                    # Csak akkor √°ll√≠tsuk BUSY-ra, ha minden √∫jrapr√≥b√°l√°s sikertelen volt
                    self.update_node_status(node.node_id, NodeStatus.BUSY)
                    raise Exception(f"Node {node.node_id} timeout: Could not reach Ollama at {url} after {max_retries + 1} attempts")
            except aiohttp.ClientError as e:
                error_msg = str(e)
                # RETRY logika: ha m√©g nem pr√≥b√°ltuk meg max_retries-szer, pr√≥b√°ljuk √∫jra
                if retry_count < max_retries and ("timeout" in error_msg.lower() or "Connection timed out" in error_msg):
                    logger.warning(f"üîå Node {node.node_id} connection timeout (attempt {retry_count + 1}/{max_retries + 1}), retrying in {retry_delay}s...")
                    await asyncio.sleep(retry_delay)
                    # Ne √°ll√≠tsuk ERROR-ra, csak BUSY-ra
                    self.update_node_status(node.node_id, NodeStatus.BUSY)
                    # √öjrapr√≥b√°l√°s
                    return await self._execute_on_node(node, model, messages, retry_count + 1)
                
                logger.error(f"‚ùå Node {node.node_id} connection error: {e}")
                # Ne √°ll√≠tsuk ERROR-ra, csak BUSY-ra (lehet, hogy ideiglenes probl√©ma)
                self.update_node_status(node.node_id, NodeStatus.BUSY)
                raise Exception(f"Node {node.node_id} connection error: {e}")
        
        except Exception as e:
            # Csak akkor √°ll√≠tsuk ERROR-ra, ha val√≥di hiba van (nem timeout/connection)
            error_msg = str(e)
            if "timeout" not in error_msg.lower() and "connection" not in error_msg.lower():
                logger.error(f"‚ùå Node {node.node_id} error: {e}")
                self.update_node_status(node.node_id, NodeStatus.ERROR)
            else:
                logger.warning(f"‚ö†Ô∏è Node {node.node_id} connection/timeout error: {e}")
                self.update_node_status(node.node_id, NodeStatus.BUSY)
            raise
    
    def _combine_responses(self, responses: List[str]) -> str:
        """T√∂bb v√°lasz kombin√°l√°sa intelligensen"""
        if not responses:
            return ""
        
        if len(responses) == 1:
            return responses[0]
        
        # Ha minden v√°lasz megegyezik, csak egyet adunk vissza
        if len(set(responses)) == 1:
            return responses[0]
        
        # V√°laszok hossza alapj√°n rendez√©s (hosszabb = r√©szletesebb)
        responses_sorted = sorted(responses, key=len, reverse=True)
        
        # Legr√©szletesebb v√°lasz + egyedi inform√°ci√≥k a t√∂bbib≈ël
        combined = responses_sorted[0]
        
        # √öj inform√°ci√≥k keres√©se a t√∂bbi v√°laszban
        base_words = set(responses_sorted[0].lower().split())
        
        for response in responses_sorted[1:]:
            response_words = set(response.lower().split())
            new_words = response_words - base_words
            
            # Ha van jelent≈ës √∫j inform√°ci√≥ (t√∂bb mint 10 egyedi sz√≥)
            if len(new_words) > 10:
                combined += f"\n\n--- Tov√°bbi inform√°ci√≥ m√°sik csom√≥pontr√≥l ---\n\n{response}"
        
        return combined
    
    def get_network_stats(self) -> Dict[str, Any]:
        """H√°l√≥zat statisztik√°k"""
        online_nodes = [n for n in self.nodes.values() if n.status == NodeStatus.ONLINE]
        total_gpu = sum(n.gpu_count for n in online_nodes)
        total_memory = sum(n.gpu_memory for n in online_nodes)
        total_cores = sum(n.cpu_cores for n in online_nodes)
        
        return {
            "total_nodes": len(self.nodes),
            "online_nodes": len(online_nodes),
            "total_gpu": total_gpu,
            "total_gpu_memory_gb": total_memory / 1024,
            "total_cpu_cores": total_cores,
            "active_tasks": len([t for t in self.tasks.values() if t.status == "processing"]),
            "completed_tasks": len([t for t in self.tasks.values() if t.status == "completed"])
        }
    
    def cleanup_old_tasks(self, max_age_hours: int = 24):
        """R√©gi feladatok t√∂rl√©se"""
        cutoff = datetime.now() - timedelta(hours=max_age_hours)
        to_remove = [
            task_id for task_id, task in self.tasks.items()
            if task.completed_at and task.completed_at < cutoff
        ]
        for task_id in to_remove:
            del self.tasks[task_id]
        logger.info(f"Cleaned up {len(to_remove)} old tasks")


# Glob√°lis h√°l√≥zat p√©ld√°ny
distributed_network = DistributedComputingNetwork()

